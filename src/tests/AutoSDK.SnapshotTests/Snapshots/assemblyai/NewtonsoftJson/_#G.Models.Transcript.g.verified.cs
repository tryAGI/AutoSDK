//HintName: G.Models.Transcript.g.cs

#pragma warning disable CS0618 // Type or member is obsolete

#nullable enable

namespace G
{
    /// <summary>
    /// A transcript object<br/>
    /// Example: {"id":"9ea68fd3-f953-42c1-9742-976c447fb463","speech_model":"","language_model":"assemblyai_default","acoustic_model":"assemblyai_default","language_code":"en_us","language_detection":true,"language_confidence_threshold":0.7,"language_confidence":0.9959,"status":"completed","audio_url":"https://github.com/AssemblyAI-Examples/audio-examples/raw/main/20230607_me_canadian_wildfires.mp3","text":"Smoke from hundreds of wildfires in Canada is triggering air quality alerts throughout the US. Skylines from Maine to Maryland to Minnesota are gray and smoggy. And in some places, the air quality warnings include the warning to stay inside. We wanted to better understand what\u0027s happening here and why, so we called Peter de Carlo, an associate professor in the Department of Environmental Health and Engineering at Johns Hopkins University Varsity. Good morning, professor. Good morning. What is it about the conditions right now that have caused this round of wildfires to affect so many people so far away? Well, there\u0027s a couple of things. The season has been pretty dry already. And then the fact that we\u0027re getting hit in the US. Is because there\u0027s a couple of weather systems that are essentially channeling the smoke from those Canadian wildfires through Pennsylvania into the Mid Atlantic and the Northeast and kind of just dropping the smoke there. So what is it in this haze that makes it harmful? And I\u0027m assuming it is harmful. It is. The levels outside right now in Baltimore are considered unhealthy. And most of that is due to what\u0027s called particulate matter, which are tiny particles, microscopic smaller than the width of your hair that can get into your lungs and impact your respiratory system, your cardiovascular system, and even your neurological your brain. What makes this particularly harmful? Is it the volume of particulant? Is it something in particular? What is it exactly? Can you just drill down on that a little bit more? Yeah. So the concentration of particulate matter I was looking at some of the monitors that we have was reaching levels of what are, in science, big 150 micrograms per meter cubed, which is more than ten times what the annual average should be and about four times higher than what you\u0027re supposed to have on a 24 hours average. And so the concentrations of these particles in the air are just much, much higher than we typically see. And exposure to those high levels can lead to a host of health problems. And who is most vulnerable? I noticed that in New York City, for example, they\u0027re canceling outdoor activities. And so here it is in the early days of summer, and they have to keep all the kids inside. So who tends to be vulnerable in a situation like this? It\u0027s the youngest. So children, obviously, whose bodies are still developing. The elderly, who are their bodies are more in decline and they\u0027re more susceptible to the health impacts of breathing, the poor air quality. And then people who have preexisting health conditions, people with respiratory conditions or heart conditions can be triggered by high levels of air pollution. Could this get worse? That\u0027s a good question. In some areas, it\u0027s much worse than others. And it just depends on kind of where the smoke is concentrated. I think New York has some of the higher concentrations right now, but that\u0027s going to change as that air moves away from the New York area. But over the course of the next few days, we will see different areas being hit at different times with the highest concentrations. I was going to ask you about more fires start burning. I don\u0027t expect the concentrations to go up too much higher. I was going to ask you how and you started to answer this, but how much longer could this last? Or forgive me if I\u0027m asking you to speculate, but what do you think? Well, I think the fires are going to burn for a little bit longer, but the key for us in the US. Is the weather system changing. And so right now, it\u0027s kind of the weather systems that are pulling that air into our mid Atlantic and Northeast region. As those weather systems change and shift, we\u0027ll see that smoke going elsewhere and not impact us in this region as much. And so I think that\u0027s going to be the defining factor. And I think the next couple of days we\u0027re going to see a shift in that weather pattern and start to push the smoke away from where we are. And finally, with the impacts of climate change, we are seeing more wildfires. Will we be seeing more of these kinds of wide ranging air quality consequences or circumstances? I mean, that is one of the predictions for climate change. Looking into the future, the fire season is starting earlier and lasting longer, and we\u0027re seeing more frequent fires. So, yeah, this is probably something that we\u0027ll be seeing more frequently. This tends to be much more of an issue in the Western US. So the eastern US. Getting hit right now is a little bit new. But yeah, I think with climate change moving forward, this is something that is going to happen more frequently. That\u0027s Peter De Carlo, associate professor in the Department of Environmental Health and Engineering at Johns Hopkins University. Sergeant Carlo, thanks so much for joining us and sharing this expertise with us. Thank you for having me.","words":[{"text":"Smoke","start":250,"end":650,"confidence":0.97465,"speaker":""},{"text":"from","start":730,"end":1022,"confidence":0.99999,"speaker":""},{"text":"hundreds","start":1076,"end":1418,"confidence":0.99844,"speaker":""},{"text":"of","start":1434,"end":1614,"confidence":0.84,"speaker":""},{"text":"wildfires","start":1652,"end":2346,"confidence":0.89572,"speaker":""},{"text":"in","start":2378,"end":2526,"confidence":0.99994,"speaker":""},{"text":"Canada","start":2548,"end":3130,"confidence":0.93953,"speaker":""},{"text":"is","start":3210,"end":3454,"confidence":0.999,"speaker":""},{"text":"triggering","start":3492,"end":3946,"confidence":0.74794,"speaker":""},{"text":"air","start":3978,"end":4174,"confidence":1,"speaker":""},{"text":"quality","start":4212,"end":4558,"confidence":0.88077,"speaker":""},{"text":"alerts","start":4644,"end":5114,"confidence":0.94814,"speaker":""},{"text":"throughout","start":5162,"end":5466,"confidence":0.99726,"speaker":""},{"text":"the","start":5498,"end":5694,"confidence":0.79,"speaker":""},{"text":"US.","start":5732,"end":6382,"confidence":0.89,"speaker":""}],"utterances":[{"confidence":0.9359033333333334,"end":26950,"speaker":"A","start":250,"text":"Smoke from hundreds of wildfires in Canada is triggering air quality alerts throughout the US. Skylines from Maine to Maryland to Minnesota are gray and smoggy. And in some places, the air quality warnings include the warning to stay inside. We wanted to better understand what\u0027s happening here and why, so we called Peter de Carlo, an associate professor in the Department of Environmental Health and Engineering at Johns Hopkins University Varsity. Good morning, professor.","words":[{"text":"Smoke","start":250,"end":650,"confidence":0.97503,"speaker":"A"},{"text":"from","start":730,"end":1022,"confidence":0.99999,"speaker":"A"},{"text":"hundreds","start":1076,"end":1418,"confidence":0.99843,"speaker":"A"},{"text":"of","start":1434,"end":1614,"confidence":0.85,"speaker":"A"},{"text":"wildfires","start":1652,"end":2346,"confidence":0.89657,"speaker":"A"},{"text":"in","start":2378,"end":2526,"confidence":0.99994,"speaker":"A"},{"text":"Canada","start":2548,"end":3130,"confidence":0.93864,"speaker":"A"},{"text":"is","start":3210,"end":3454,"confidence":0.999,"speaker":"A"},{"text":"triggering","start":3492,"end":3946,"confidence":0.75366,"speaker":"A"},{"text":"air","start":3978,"end":4174,"confidence":1,"speaker":"A"},{"text":"quality","start":4212,"end":4558,"confidence":0.87745,"speaker":"A"},{"text":"alerts","start":4644,"end":5114,"confidence":0.94739,"speaker":"A"},{"text":"throughout","start":5162,"end":5466,"confidence":0.99726,"speaker":"A"},{"text":"the","start":5498,"end":5694,"confidence":0.79,"speaker":"A"},{"text":"US.","start":5732,"end":6382,"confidence":0.88,"speaker":"A"}]}],"confidence":0.9404651451800253,"audio_duration":281,"punctuate":true,"format_text":true,"dual_channel":false,"webhook_url":"https://your-webhook-url.tld/path","webhook_status_code":200,"webhook_auth":true,"webhook_auth_header_name":"webhook-secret","auto_highlights_result":{"status":"success","results":[{"count":1,"rank":0.08,"text":"air quality alerts","timestamps":[{"start":3978,"end":5114}]},{"count":1,"rank":0.08,"text":"wide ranging air quality consequences","timestamps":[{"start":235388,"end":238694}]},{"count":1,"rank":0.07,"text":"more wildfires","timestamps":[{"start":230972,"end":232354}]},{"count":1,"rank":0.07,"text":"air pollution","timestamps":[{"start":156004,"end":156910}]},{"count":3,"rank":0.07,"text":"weather systems","timestamps":[{"start":47344,"end":47958},{"start":205268,"end":205818},{"start":211588,"end":213434}]},{"count":2,"rank":0.06,"text":"high levels","timestamps":[{"start":121128,"end":121646},{"start":155412,"end":155866}]},{"count":1,"rank":0.06,"text":"health conditions","timestamps":[{"start":152138,"end":152666}]},{"count":2,"rank":0.06,"text":"Peter de Carlo","timestamps":[{"start":18948,"end":19930},{"start":268298,"end":269194}]},{"count":1,"rank":0.06,"text":"New York City","timestamps":[{"start":125768,"end":126274}]},{"count":1,"rank":0.05,"text":"respiratory conditions","timestamps":[{"start":152964,"end":153786}]},{"count":3,"rank":0.05,"text":"New York","timestamps":[{"start":125768,"end":126034},{"start":171448,"end":171938},{"start":176008,"end":176322}]},{"count":3,"rank":0.05,"text":"climate change","timestamps":[{"start":229548,"end":230230},{"start":244576,"end":245162},{"start":263348,"end":263950}]},{"count":1,"rank":0.05,"text":"Johns Hopkins University Varsity","timestamps":[{"start":23972,"end":25490}]},{"count":1,"rank":0.05,"text":"heart conditions","timestamps":[{"start":153988,"end":154506}]},{"count":1,"rank":0.05,"text":"air quality warnings","timestamps":[{"start":12308,"end":13434}]}]},"auto_highlights":true,"audio_start_from":10,"audio_end_at":280,"word_boost":["aws","azure","google cloud"],"boost_param":"high","filter_profanity":true,"redact_pii":true,"redact_pii_audio":true,"redact_pii_audio_quality":"mp3","redact_pii_policies":["us_social_security_number","credit_card_number"],"redact_pii_sub":"hash","speaker_labels":true,"content_safety":true,"iab_categories":true,"content_safety_labels":{"status":"success","results":[{"text":"Smoke from hundreds of wildfires in Canada is triggering air quality alerts throughout the US. Skylines from Maine to Maryland to Minnesota are gray and smoggy. And in some places, the air quality warnings include the warning to stay inside. We wanted to better understand what\u0027s happening here and why, so we called Peter de Carlo, an associate professor in the Department of Environmental Health and Engineering at Johns Hopkins University Varsity. Good morning, professor. Good morning.","labels":[{"label":"disasters","confidence":0.8142836093902588,"severity":0.4093044400215149}],"sentences_idx_start":0,"sentences_idx_end":5,"timestamp":{"start":250,"end":28840}}],"summary":{"disasters":0.9940800441842205,"health_issues":0.9216489289040967},"severity_score_summary":{"disasters":{"low":0.5733263024656846,"medium":0.42667369753431533,"high":0},"health_issues":{"low":0.22863814977924785,"medium":0.45014154926938227,"high":0.32122030095136983}}},"iab_categories_result":{"status":"success","results":[{"text":"Smoke from hundreds of wildfires in Canada is triggering air quality alerts throughout the US. Skylines from Maine to Maryland to Minnesota are gray and smoggy. And in some places, the air quality warnings include the warning to stay inside. We wanted to better understand what\u0027s happening here and why, so we called Peter de Carlo, an associate professor in the Department of Environmental Health and Engineering at Johns Hopkins University Varsity. Good morning, professor. Good morning.","labels":[{"relevance":0.988274097442627,"label":"Home\u0026Garden\u003EIndoorEnvironmentalQuality"},{"relevance":0.5821335911750793,"label":"NewsAndPolitics\u003EWeather"},{"relevance":0.0042327106930315495,"label":"MedicalHealth\u003EDiseasesAndConditions\u003ELungAndRespiratoryHealth"},{"relevance":0.0033971222583204508,"label":"NewsAndPolitics\u003EDisasters"},{"relevance":0.002469958271831274,"label":"BusinessAndFinance\u003EBusiness\u003EGreenSolutions"},{"relevance":0.0014376690378412604,"label":"MedicalHealth\u003EDiseasesAndConditions\u003ECancer"},{"relevance":0.0014294233405962586,"label":"Science\u003EEnvironment"},{"relevance":0.001234519761055708,"label":"Travel\u003ETravelLocations\u003EPolarTravel"},{"relevance":0.0010231725173071027,"label":"MedicalHealth\u003EDiseasesAndConditions\u003EColdAndFlu"},{"relevance":0.0007445293595083058,"label":"BusinessAndFinance\u003EIndustries\u003EPowerAndEnergyIndustry"}],"timestamp":{"start":250,"end":28840}}],"summary":{"NewsAndPolitics\u003EWeather":1,"Home\u0026Garden\u003EIndoorEnvironmentalQuality":0.9043831825256348,"Science\u003EEnvironment":0.16117265820503235,"BusinessAndFinance\u003EIndustries\u003EEnvironmentalServicesIndustry":0.14393523335456848,"MedicalHealth\u003EDiseasesAndConditions\u003ELungAndRespiratoryHealth":0.11401086300611496,"BusinessAndFinance\u003EBusiness\u003EGreenSolutions":0.06348437070846558,"NewsAndPolitics\u003EDisasters":0.05041387677192688,"Travel\u003ETravelLocations\u003EPolarTravel":0.01308488193899393,"HealthyLiving":0.008222488686442375,"MedicalHealth\u003EDiseasesAndConditions\u003EColdAndFlu":0.0022315620444715023,"MedicalHealth\u003EDiseasesAndConditions\u003EHeartAndCardiovascularDiseases":0.00213034451007843,"HealthyLiving\u003EWellness\u003ESmokingCessation":0.001540527562610805,"MedicalHealth\u003EDiseasesAndConditions\u003EInjuries":0.0013950627762824297,"BusinessAndFinance\u003EIndustries\u003EPowerAndEnergyIndustry":0.0012570273829624057,"MedicalHealth\u003EDiseasesAndConditions\u003ECancer":0.001097781932912767,"MedicalHealth\u003EDiseasesAndConditions\u003EAllergies":0.0010148967849090695,"MedicalHealth\u003EDiseasesAndConditions\u003EMentalHealth":0.000717321818228811,"Style\u0026Fashion\u003EPersonalCare\u003EDeodorantAndAntiperspirant":0.0006022014422342181,"Technology\u0026Computing\u003EComputing\u003EComputerNetworking":0.0005461975233629346,"MedicalHealth\u003EDiseasesAndConditions\u003EInjuries\u003EFirstAid":0.0004885646631009877}},"custom_spelling":"","throttled":"","auto_chapters":true,"summarization":true,"summary_type":"bullets","summary_model":"informative","custom_topics":true,"topics":[],"speech_threshold":0.5,"disfluencies":false,"sentiment_analysis":true,"chapters":[{"summary":"Smoke from hundreds of wildfires in Canada is triggering air quality alerts throughout the US. Skylines from Maine to Maryland to Minnesota are gray and smoggy. In some places, the air quality warnings include the warning to stay inside.","gist":"Smoggy air quality alerts across US","headline":"Smoke from hundreds of wildfires in Canada is triggering air quality alerts across US","start":250,"end":28840},{"summary":"Air pollution levels in Baltimore are considered unhealthy. Exposure to high levels can lead to a host of health problems. With climate change, we are seeing more wildfires. Will we be seeing more of these kinds of wide ranging air quality consequences?","gist":"What is it about the conditions right now that have caused this round","headline":"High particulate matter in wildfire smoke can lead to serious health problems","start":29610,"end":280340}],"sentiment_analysis_results":"","entity_detection":true,"entities":[{"entity_type":"location","text":"Canada","start":2548,"end":3130},{"entity_type":"location","text":"the US","start":5498,"end":6382},{"entity_type":"location","text":"Maine","start":7492,"end":7914},{"entity_type":"location","text":"Maryland","start":8212,"end":8634},{"entity_type":"location","text":"Minnesota","start":8932,"end":9578},{"entity_type":"person_name","text":"Peter de Carlo","start":18948,"end":19930},{"entity_type":"occupation","text":"associate professor","start":20292,"end":21194},{"entity_type":"organization","text":"Department of Environmental Health and Engineering","start":21508,"end":23706},{"entity_type":"organization","text":"Johns Hopkins University Varsity","start":23972,"end":25490},{"entity_type":"occupation","text":"professor","start":26076,"end":26950},{"entity_type":"location","text":"the US","start":45184,"end":45898},{"entity_type":"nationality","text":"Canadian","start":49728,"end":50086}],"summary":"- Smoke from hundreds of wildfires in Canada is triggering air quality alerts throughout the US. Skylines from Maine to Maryland to Minnesota are gray and smoggy. In some places, the air quality warnings include the warning to stay inside.\\n- Air pollution levels in Baltimore are considered unhealthy. Exposure to high levels can lead to a host of health problems. With climate change, we are seeing more wildfires. Will we be seeing more of these kinds of wide ranging air quality consequences?","speakers_expected":2}
    /// </summary>
    public sealed partial class Transcript
    {
        /// <summary>
        /// The unique identifier of your transcript
        /// </summary>
        [global::Newtonsoft.Json.JsonProperty("id", Required = global::Newtonsoft.Json.Required.Always)]
        public global::System.Guid Id { get; set; } = default!;

        /// <summary>
        /// The URL of the media that was transcribed
        /// </summary>
        [global::Newtonsoft.Json.JsonProperty("audio_url", Required = global::Newtonsoft.Json.Required.Always)]
        public string AudioUrl { get; set; } = default!;

        /// <summary>
        /// The status of your transcript. Possible values are queued, processing, completed, or error.
        /// </summary>
        [global::Newtonsoft.Json.JsonProperty("status", Required = global::Newtonsoft.Json.Required.Always)]
        public global::G.TranscriptStatus Status { get; set; } = default!;

        /// <summary>
        /// The language of your audio file.<br/>
        /// Possible values are found in [Supported Languages](https://www.assemblyai.com/docs/concepts/supported-languages).<br/>
        /// The default value is 'en_us'.
        /// </summary>
        [global::Newtonsoft.Json.JsonProperty("language_code")]
        public global::G.AnyOf<global::G.TranscriptLanguageCode?, string>? LanguageCode { get; set; }

        /// <summary>
        /// Whether [Automatic language detection](https://www.assemblyai.com/docs/models/speech-recognition#automatic-language-detection) is enabled, either true or false
        /// </summary>
        [global::Newtonsoft.Json.JsonProperty("language_detection")]
        public object? LanguageDetection { get; set; }

        /// <summary>
        /// The confidence threshold for the automatically detected language.<br/>
        /// An error will be returned if the language confidence is below this threshold.
        /// </summary>
        [global::Newtonsoft.Json.JsonProperty("language_confidence_threshold", Required = global::Newtonsoft.Json.Required.Always)]
        public float LanguageConfidenceThreshold { get; set; } = default!;

        /// <summary>
        /// The confidence score for the detected language, between 0.0 (low confidence) and 1.0 (high confidence)
        /// </summary>
        [global::Newtonsoft.Json.JsonProperty("language_confidence", Required = global::Newtonsoft.Json.Required.Always)]
        public double LanguageConfidence { get; set; } = default!;

        /// <summary>
        /// The speech model used for the transcription. When `null`, the default model is used.
        /// </summary>
        [global::Newtonsoft.Json.JsonProperty("speech_model", Required = global::Newtonsoft.Json.Required.Always)]
        public global::G.OneOf<global::G.SpeechModel2?, object> SpeechModel { get; set; } = default!;

        /// <summary>
        /// The textual transcript of your media file
        /// </summary>
        [global::Newtonsoft.Json.JsonProperty("text")]
        public object? Text { get; set; }

        /// <summary>
        /// An array of temporally-sequential word objects, one for each word in the transcript.<br/>
        /// See [Speech recognition](https://www.assemblyai.com/docs/models/speech-recognition) for more information.
        /// </summary>
        [global::Newtonsoft.Json.JsonProperty("words")]
        public global::System.Collections.Generic.IList<global::G.TranscriptWord>? Words { get; set; }

        /// <summary>
        /// When dual_channel or speaker_labels is enabled, a list of turn-by-turn utterance objects.<br/>
        /// See [Speaker diarization](https://www.assemblyai.com/docs/models/speaker-diarization) for more information.
        /// </summary>
        [global::Newtonsoft.Json.JsonProperty("utterances")]
        public global::System.Collections.Generic.IList<global::G.TranscriptUtterance>? Utterances { get; set; }

        /// <summary>
        /// The confidence score for the transcript, between 0.0 (low confidence) and 1.0 (high confidence)
        /// </summary>
        [global::Newtonsoft.Json.JsonProperty("confidence")]
        public double? Confidence { get; set; }

        /// <summary>
        /// The duration of this transcript object's media file, in seconds
        /// </summary>
        [global::Newtonsoft.Json.JsonProperty("audio_duration")]
        public object? AudioDuration { get; set; }

        /// <summary>
        /// Whether Automatic Punctuation is enabled, either true or false
        /// </summary>
        [global::Newtonsoft.Json.JsonProperty("punctuate")]
        public object? Punctuate { get; set; }

        /// <summary>
        /// Whether Text Formatting is enabled, either true or false
        /// </summary>
        [global::Newtonsoft.Json.JsonProperty("format_text")]
        public object? FormatText { get; set; }

        /// <summary>
        /// Transcribe Filler Words, like "umm", in your media file; can be true or false
        /// </summary>
        [global::Newtonsoft.Json.JsonProperty("disfluencies")]
        public object? Disfluencies { get; set; }

        /// <summary>
        /// Whether [Dual channel transcription](https://www.assemblyai.com/docs/models/speech-recognition#dual-channel-transcription) was enabled in the transcription request, either true or false
        /// </summary>
        [global::Newtonsoft.Json.JsonProperty("dual_channel")]
        public object? DualChannel { get; set; }

        /// <summary>
        /// The URL to which we send webhook requests.<br/>
        /// We sends two different types of webhook requests.<br/>
        /// One request when a transcript is completed or failed, and one request when the redacted audio is ready if redact_pii_audio is enabled.
        /// </summary>
        [global::Newtonsoft.Json.JsonProperty("webhook_url")]
        public string? WebhookUrl { get; set; }

        /// <summary>
        /// The status code we received from your server when delivering the transcript completed or failed webhook request, if a webhook URL was provided
        /// </summary>
        [global::Newtonsoft.Json.JsonProperty("webhook_status_code")]
        public object? WebhookStatusCode { get; set; }

        /// <summary>
        /// Whether webhook authentication details were provided
        /// </summary>
        [global::Newtonsoft.Json.JsonProperty("webhook_auth", Required = global::Newtonsoft.Json.Required.Always)]
        public bool WebhookAuth { get; set; } = default!;

        /// <summary>
        /// The header name to be sent with the transcript completed or failed webhook requests
        /// </summary>
        [global::Newtonsoft.Json.JsonProperty("webhook_auth_header_name")]
        public object? WebhookAuthHeaderName { get; set; }

        /// <summary>
        /// Whether speed boost is enabled
        /// </summary>
        [global::Newtonsoft.Json.JsonProperty("speed_boost")]
        [global::System.Obsolete("This property marked as deprecated.")]
        public object? SpeedBoost { get; set; }

        /// <summary>
        /// Whether Key Phrases is enabled, either true or false
        /// </summary>
        [global::Newtonsoft.Json.JsonProperty("auto_highlights", Required = global::Newtonsoft.Json.Required.Always)]
        public bool AutoHighlights { get; set; } = default!;

        /// <summary>
        /// An array of results for the Key Phrases model, if it is enabled.<br/>
        /// See [Key Phrases](https://www.assemblyai.com/docs/models/key-phrases) for more information.
        /// </summary>
        [global::Newtonsoft.Json.JsonProperty("auto_highlights_result")]
        public global::G.OneOf<global::G.AutoHighlightsResult2, object>? AutoHighlightsResult { get; set; }

        /// <summary>
        /// The point in time, in milliseconds, in the file at which the transcription was started
        /// </summary>
        [global::Newtonsoft.Json.JsonProperty("audio_start_from")]
        public object? AudioStartFrom { get; set; }

        /// <summary>
        /// The point in time, in milliseconds, in the file at which the transcription was terminated
        /// </summary>
        [global::Newtonsoft.Json.JsonProperty("audio_end_at")]
        public object? AudioEndAt { get; set; }

        /// <summary>
        /// The list of custom vocabulary to boost transcription probability for
        /// </summary>
        [global::Newtonsoft.Json.JsonProperty("word_boost")]
        public global::System.Collections.Generic.IList<string>? WordBoost { get; set; }

        /// <summary>
        /// The word boost parameter value
        /// </summary>
        [global::Newtonsoft.Json.JsonProperty("boost_param")]
        public object? BoostParam { get; set; }

        /// <summary>
        /// Whether [Profanity Filtering](https://www.assemblyai.com/docs/models/speech-recognition#profanity-filtering) is enabled, either true or false
        /// </summary>
        [global::Newtonsoft.Json.JsonProperty("filter_profanity")]
        public object? FilterProfanity { get; set; }

        /// <summary>
        /// Whether [PII Redaction](https://www.assemblyai.com/docs/models/pii-redaction) is enabled, either true or false
        /// </summary>
        [global::Newtonsoft.Json.JsonProperty("redact_pii", Required = global::Newtonsoft.Json.Required.Always)]
        public bool RedactPii { get; set; } = default!;

        /// <summary>
        /// Whether a redacted version of the audio file was generated,<br/>
        /// either true or false. See [PII redaction](https://www.assemblyai.com/docs/models/pii-redaction) for more information.
        /// </summary>
        [global::Newtonsoft.Json.JsonProperty("redact_pii_audio")]
        public object? RedactPiiAudio { get; set; }

        /// <summary>
        /// The audio quality of the PII-redacted audio file, if redact_pii_audio is enabled.<br/>
        /// See [PII redaction](https://www.assemblyai.com/docs/models/pii-redaction) for more information.
        /// </summary>
        [global::Newtonsoft.Json.JsonProperty("redact_pii_audio_quality")]
        public global::G.OneOf<global::G.RedactPiiAudioQuality?, object>? RedactPiiAudioQuality { get; set; }

        /// <summary>
        /// The list of PII Redaction policies that were enabled, if PII Redaction is enabled.<br/>
        /// See [PII redaction](https://www.assemblyai.com/docs/models/pii-redaction) for more information.
        /// </summary>
        [global::Newtonsoft.Json.JsonProperty("redact_pii_policies")]
        public global::System.Collections.Generic.IList<global::G.PiiPolicy>? RedactPiiPolicies { get; set; }

        /// <summary>
        /// The replacement logic for detected PII, can be "entity_name" or "hash". See [PII redaction](https://www.assemblyai.com/docs/models/pii-redaction) for more details.
        /// </summary>
        [global::Newtonsoft.Json.JsonProperty("redact_pii_sub")]
        public global::G.SubstitutionPolicy? RedactPiiSub { get; set; }

        /// <summary>
        /// Whether [Speaker diarization](https://www.assemblyai.com/docs/models/speaker-diarization) is enabled, can be true or false
        /// </summary>
        [global::Newtonsoft.Json.JsonProperty("speaker_labels")]
        public object? SpeakerLabels { get; set; }

        /// <summary>
        /// Tell the speaker label model how many speakers it should attempt to identify, up to 10. See [Speaker diarization](https://www.assemblyai.com/docs/models/speaker-diarization) for more details.
        /// </summary>
        [global::Newtonsoft.Json.JsonProperty("speakers_expected")]
        public object? SpeakersExpected { get; set; }

        /// <summary>
        /// Whether [Content Moderation](https://www.assemblyai.com/docs/models/content-moderation) is enabled, can be true or false
        /// </summary>
        [global::Newtonsoft.Json.JsonProperty("content_safety")]
        public object? ContentSafety { get; set; }

        /// <summary>
        /// An array of results for the Content Moderation model, if it is enabled.<br/>
        /// See [Content moderation](https://www.assemblyai.com/docs/models/content-moderation) for more information.
        /// </summary>
        [global::Newtonsoft.Json.JsonProperty("content_safety_labels")]
        public global::G.OneOf<global::G.ContentSafetyLabelsResult, object>? ContentSafetyLabels { get; set; }

        /// <summary>
        /// Whether [Topic Detection](https://www.assemblyai.com/docs/models/topic-detection) is enabled, can be true or false
        /// </summary>
        [global::Newtonsoft.Json.JsonProperty("iab_categories")]
        public object? IabCategories { get; set; }

        /// <summary>
        /// The result of the Topic Detection model, if it is enabled.<br/>
        /// See [Topic Detection](https://www.assemblyai.com/docs/models/topic-detection) for more information.
        /// </summary>
        [global::Newtonsoft.Json.JsonProperty("iab_categories_result")]
        public global::G.OneOf<global::G.TopicDetectionModelResult, object>? IabCategoriesResult { get; set; }

        /// <summary>
        /// Customize how words are spelled and formatted using to and from values
        /// </summary>
        [global::Newtonsoft.Json.JsonProperty("custom_spelling")]
        public global::System.Collections.Generic.IList<global::G.TranscriptCustomSpelling>? CustomSpelling { get; set; }

        /// <summary>
        /// Whether [Auto Chapters](https://www.assemblyai.com/docs/models/auto-chapters) is enabled, can be true or false
        /// </summary>
        [global::Newtonsoft.Json.JsonProperty("auto_chapters")]
        public object? AutoChapters { get; set; }

        /// <summary>
        /// An array of temporally sequential chapters for the audio file
        /// </summary>
        [global::Newtonsoft.Json.JsonProperty("chapters")]
        public global::System.Collections.Generic.IList<global::G.Chapter>? Chapters { get; set; }

        /// <summary>
        /// Whether [Summarization](https://www.assemblyai.com/docs/models/summarization) is enabled, either true or false
        /// </summary>
        [global::Newtonsoft.Json.JsonProperty("summarization", Required = global::Newtonsoft.Json.Required.Always)]
        public bool Summarization { get; set; } = default!;

        /// <summary>
        /// The type of summary generated, if [Summarization](https://www.assemblyai.com/docs/models/summarization) is enabled
        /// </summary>
        [global::Newtonsoft.Json.JsonProperty("summary_type")]
        public object? SummaryType { get; set; }

        /// <summary>
        /// The Summarization model used to generate the summary,<br/>
        /// if [Summarization](https://www.assemblyai.com/docs/models/summarization) is enabled
        /// </summary>
        [global::Newtonsoft.Json.JsonProperty("summary_model")]
        public object? SummaryModel { get; set; }

        /// <summary>
        /// The generated summary of the media file, if [Summarization](https://www.assemblyai.com/docs/models/summarization) is enabled
        /// </summary>
        [global::Newtonsoft.Json.JsonProperty("summary")]
        public object? Summary { get; set; }

        /// <summary>
        /// Whether custom topics is enabled, either true or false
        /// </summary>
        [global::Newtonsoft.Json.JsonProperty("custom_topics")]
        public object? CustomTopics { get; set; }

        /// <summary>
        /// The list of custom topics provided if custom topics is enabled
        /// </summary>
        [global::Newtonsoft.Json.JsonProperty("topics")]
        public global::System.Collections.Generic.IList<string>? Topics { get; set; }

        /// <summary>
        /// Whether [Sentiment Analysis](https://www.assemblyai.com/docs/models/sentiment-analysis) is enabled, can be true or false
        /// </summary>
        [global::Newtonsoft.Json.JsonProperty("sentiment_analysis")]
        public object? SentimentAnalysis { get; set; }

        /// <summary>
        /// An array of results for the Sentiment Analysis model, if it is enabled.<br/>
        /// See [Sentiment Analysis](https://www.assemblyai.com/docs/models/sentiment-analysis) for more information.
        /// </summary>
        [global::Newtonsoft.Json.JsonProperty("sentiment_analysis_results")]
        public global::System.Collections.Generic.IList<global::G.SentimentAnalysisResult>? SentimentAnalysisResults { get; set; }

        /// <summary>
        /// Whether [Entity Detection](https://www.assemblyai.com/docs/models/entity-detection) is enabled, can be true or false
        /// </summary>
        [global::Newtonsoft.Json.JsonProperty("entity_detection")]
        public object? EntityDetection { get; set; }

        /// <summary>
        /// An array of results for the Entity Detection model, if it is enabled.<br/>
        /// See [Entity detection](https://www.assemblyai.com/docs/models/entity-detection) for more information.
        /// </summary>
        [global::Newtonsoft.Json.JsonProperty("entities")]
        public global::System.Collections.Generic.IList<global::G.Entity>? Entities { get; set; }

        /// <summary>
        /// Defaults to null. Reject audio files that contain less than this fraction of speech.<br/>
        /// Valid values are in the range [0, 1] inclusive.
        /// </summary>
        [global::Newtonsoft.Json.JsonProperty("speech_threshold")]
        public float? SpeechThreshold { get; set; }

        /// <summary>
        /// True while a request is throttled and false when a request is no longer throttled
        /// </summary>
        [global::Newtonsoft.Json.JsonProperty("throttled")]
        public object? Throttled { get; set; }

        /// <summary>
        /// Error message of why the transcript failed
        /// </summary>
        [global::Newtonsoft.Json.JsonProperty("error")]
        public string? Error { get; set; }

        /// <summary>
        /// The language model that was used for the transcript
        /// </summary>
        [global::Newtonsoft.Json.JsonProperty("language_model", Required = global::Newtonsoft.Json.Required.Always)]
        public string LanguageModel { get; set; } = default!;

        /// <summary>
        /// The acoustic model that was used for the transcript
        /// </summary>
        [global::Newtonsoft.Json.JsonProperty("acoustic_model", Required = global::Newtonsoft.Json.Required.Always)]
        public string AcousticModel { get; set; } = default!;

        /// <summary>
        /// Additional properties that are not explicitly defined in the schema
        /// </summary>
        [global::Newtonsoft.Json.JsonExtensionData]
        public global::System.Collections.Generic.IDictionary<string, object> AdditionalProperties { get; set; } = new global::System.Collections.Generic.Dictionary<string, object>();

        /// <summary>
        /// Initializes a new instance of the <see cref="Transcript" /> class.
        /// </summary>
        /// <param name="id">
        /// The unique identifier of your transcript
        /// </param>
        /// <param name="audioUrl">
        /// The URL of the media that was transcribed
        /// </param>
        /// <param name="status">
        /// The status of your transcript. Possible values are queued, processing, completed, or error.
        /// </param>
        /// <param name="languageCode">
        /// The language of your audio file.<br/>
        /// Possible values are found in [Supported Languages](https://www.assemblyai.com/docs/concepts/supported-languages).<br/>
        /// The default value is 'en_us'.
        /// </param>
        /// <param name="languageDetection">
        /// Whether [Automatic language detection](https://www.assemblyai.com/docs/models/speech-recognition#automatic-language-detection) is enabled, either true or false
        /// </param>
        /// <param name="languageConfidenceThreshold">
        /// The confidence threshold for the automatically detected language.<br/>
        /// An error will be returned if the language confidence is below this threshold.
        /// </param>
        /// <param name="languageConfidence">
        /// The confidence score for the detected language, between 0.0 (low confidence) and 1.0 (high confidence)
        /// </param>
        /// <param name="speechModel">
        /// The speech model used for the transcription. When `null`, the default model is used.
        /// </param>
        /// <param name="text">
        /// The textual transcript of your media file
        /// </param>
        /// <param name="words">
        /// An array of temporally-sequential word objects, one for each word in the transcript.<br/>
        /// See [Speech recognition](https://www.assemblyai.com/docs/models/speech-recognition) for more information.
        /// </param>
        /// <param name="utterances">
        /// When dual_channel or speaker_labels is enabled, a list of turn-by-turn utterance objects.<br/>
        /// See [Speaker diarization](https://www.assemblyai.com/docs/models/speaker-diarization) for more information.
        /// </param>
        /// <param name="confidence">
        /// The confidence score for the transcript, between 0.0 (low confidence) and 1.0 (high confidence)
        /// </param>
        /// <param name="audioDuration">
        /// The duration of this transcript object's media file, in seconds
        /// </param>
        /// <param name="punctuate">
        /// Whether Automatic Punctuation is enabled, either true or false
        /// </param>
        /// <param name="formatText">
        /// Whether Text Formatting is enabled, either true or false
        /// </param>
        /// <param name="disfluencies">
        /// Transcribe Filler Words, like "umm", in your media file; can be true or false
        /// </param>
        /// <param name="dualChannel">
        /// Whether [Dual channel transcription](https://www.assemblyai.com/docs/models/speech-recognition#dual-channel-transcription) was enabled in the transcription request, either true or false
        /// </param>
        /// <param name="webhookUrl">
        /// The URL to which we send webhook requests.<br/>
        /// We sends two different types of webhook requests.<br/>
        /// One request when a transcript is completed or failed, and one request when the redacted audio is ready if redact_pii_audio is enabled.
        /// </param>
        /// <param name="webhookStatusCode">
        /// The status code we received from your server when delivering the transcript completed or failed webhook request, if a webhook URL was provided
        /// </param>
        /// <param name="webhookAuth">
        /// Whether webhook authentication details were provided
        /// </param>
        /// <param name="webhookAuthHeaderName">
        /// The header name to be sent with the transcript completed or failed webhook requests
        /// </param>
        /// <param name="autoHighlights">
        /// Whether Key Phrases is enabled, either true or false
        /// </param>
        /// <param name="autoHighlightsResult">
        /// An array of results for the Key Phrases model, if it is enabled.<br/>
        /// See [Key Phrases](https://www.assemblyai.com/docs/models/key-phrases) for more information.
        /// </param>
        /// <param name="audioStartFrom">
        /// The point in time, in milliseconds, in the file at which the transcription was started
        /// </param>
        /// <param name="audioEndAt">
        /// The point in time, in milliseconds, in the file at which the transcription was terminated
        /// </param>
        /// <param name="wordBoost">
        /// The list of custom vocabulary to boost transcription probability for
        /// </param>
        /// <param name="boostParam">
        /// The word boost parameter value
        /// </param>
        /// <param name="filterProfanity">
        /// Whether [Profanity Filtering](https://www.assemblyai.com/docs/models/speech-recognition#profanity-filtering) is enabled, either true or false
        /// </param>
        /// <param name="redactPii">
        /// Whether [PII Redaction](https://www.assemblyai.com/docs/models/pii-redaction) is enabled, either true or false
        /// </param>
        /// <param name="redactPiiAudio">
        /// Whether a redacted version of the audio file was generated,<br/>
        /// either true or false. See [PII redaction](https://www.assemblyai.com/docs/models/pii-redaction) for more information.
        /// </param>
        /// <param name="redactPiiAudioQuality">
        /// The audio quality of the PII-redacted audio file, if redact_pii_audio is enabled.<br/>
        /// See [PII redaction](https://www.assemblyai.com/docs/models/pii-redaction) for more information.
        /// </param>
        /// <param name="redactPiiPolicies">
        /// The list of PII Redaction policies that were enabled, if PII Redaction is enabled.<br/>
        /// See [PII redaction](https://www.assemblyai.com/docs/models/pii-redaction) for more information.
        /// </param>
        /// <param name="redactPiiSub">
        /// The replacement logic for detected PII, can be "entity_name" or "hash". See [PII redaction](https://www.assemblyai.com/docs/models/pii-redaction) for more details.
        /// </param>
        /// <param name="speakerLabels">
        /// Whether [Speaker diarization](https://www.assemblyai.com/docs/models/speaker-diarization) is enabled, can be true or false
        /// </param>
        /// <param name="speakersExpected">
        /// Tell the speaker label model how many speakers it should attempt to identify, up to 10. See [Speaker diarization](https://www.assemblyai.com/docs/models/speaker-diarization) for more details.
        /// </param>
        /// <param name="contentSafety">
        /// Whether [Content Moderation](https://www.assemblyai.com/docs/models/content-moderation) is enabled, can be true or false
        /// </param>
        /// <param name="contentSafetyLabels">
        /// An array of results for the Content Moderation model, if it is enabled.<br/>
        /// See [Content moderation](https://www.assemblyai.com/docs/models/content-moderation) for more information.
        /// </param>
        /// <param name="iabCategories">
        /// Whether [Topic Detection](https://www.assemblyai.com/docs/models/topic-detection) is enabled, can be true or false
        /// </param>
        /// <param name="iabCategoriesResult">
        /// The result of the Topic Detection model, if it is enabled.<br/>
        /// See [Topic Detection](https://www.assemblyai.com/docs/models/topic-detection) for more information.
        /// </param>
        /// <param name="customSpelling">
        /// Customize how words are spelled and formatted using to and from values
        /// </param>
        /// <param name="autoChapters">
        /// Whether [Auto Chapters](https://www.assemblyai.com/docs/models/auto-chapters) is enabled, can be true or false
        /// </param>
        /// <param name="chapters">
        /// An array of temporally sequential chapters for the audio file
        /// </param>
        /// <param name="summarization">
        /// Whether [Summarization](https://www.assemblyai.com/docs/models/summarization) is enabled, either true or false
        /// </param>
        /// <param name="summaryType">
        /// The type of summary generated, if [Summarization](https://www.assemblyai.com/docs/models/summarization) is enabled
        /// </param>
        /// <param name="summaryModel">
        /// The Summarization model used to generate the summary,<br/>
        /// if [Summarization](https://www.assemblyai.com/docs/models/summarization) is enabled
        /// </param>
        /// <param name="summary">
        /// The generated summary of the media file, if [Summarization](https://www.assemblyai.com/docs/models/summarization) is enabled
        /// </param>
        /// <param name="customTopics">
        /// Whether custom topics is enabled, either true or false
        /// </param>
        /// <param name="topics">
        /// The list of custom topics provided if custom topics is enabled
        /// </param>
        /// <param name="sentimentAnalysis">
        /// Whether [Sentiment Analysis](https://www.assemblyai.com/docs/models/sentiment-analysis) is enabled, can be true or false
        /// </param>
        /// <param name="sentimentAnalysisResults">
        /// An array of results for the Sentiment Analysis model, if it is enabled.<br/>
        /// See [Sentiment Analysis](https://www.assemblyai.com/docs/models/sentiment-analysis) for more information.
        /// </param>
        /// <param name="entityDetection">
        /// Whether [Entity Detection](https://www.assemblyai.com/docs/models/entity-detection) is enabled, can be true or false
        /// </param>
        /// <param name="entities">
        /// An array of results for the Entity Detection model, if it is enabled.<br/>
        /// See [Entity detection](https://www.assemblyai.com/docs/models/entity-detection) for more information.
        /// </param>
        /// <param name="speechThreshold">
        /// Defaults to null. Reject audio files that contain less than this fraction of speech.<br/>
        /// Valid values are in the range [0, 1] inclusive.
        /// </param>
        /// <param name="throttled">
        /// True while a request is throttled and false when a request is no longer throttled
        /// </param>
        /// <param name="error">
        /// Error message of why the transcript failed
        /// </param>
        /// <param name="languageModel">
        /// The language model that was used for the transcript
        /// </param>
        /// <param name="acousticModel">
        /// The acoustic model that was used for the transcript
        /// </param>
        public Transcript(
            global::System.Guid id,
            string audioUrl,
            global::G.TranscriptStatus status,
            float languageConfidenceThreshold,
            double languageConfidence,
            global::G.OneOf<global::G.SpeechModel2?, object> speechModel,
            bool webhookAuth,
            bool autoHighlights,
            bool redactPii,
            bool summarization,
            string languageModel,
            string acousticModel,
            global::G.AnyOf<global::G.TranscriptLanguageCode?, string>? languageCode,
            object? languageDetection,
            object? text,
            global::System.Collections.Generic.IList<global::G.TranscriptWord>? words,
            global::System.Collections.Generic.IList<global::G.TranscriptUtterance>? utterances,
            double? confidence,
            object? audioDuration,
            object? punctuate,
            object? formatText,
            object? disfluencies,
            object? dualChannel,
            string? webhookUrl,
            object? webhookStatusCode,
            object? webhookAuthHeaderName,
            global::G.OneOf<global::G.AutoHighlightsResult2, object>? autoHighlightsResult,
            object? audioStartFrom,
            object? audioEndAt,
            global::System.Collections.Generic.IList<string>? wordBoost,
            object? boostParam,
            object? filterProfanity,
            object? redactPiiAudio,
            global::G.OneOf<global::G.RedactPiiAudioQuality?, object>? redactPiiAudioQuality,
            global::System.Collections.Generic.IList<global::G.PiiPolicy>? redactPiiPolicies,
            global::G.SubstitutionPolicy? redactPiiSub,
            object? speakerLabels,
            object? speakersExpected,
            object? contentSafety,
            global::G.OneOf<global::G.ContentSafetyLabelsResult, object>? contentSafetyLabels,
            object? iabCategories,
            global::G.OneOf<global::G.TopicDetectionModelResult, object>? iabCategoriesResult,
            global::System.Collections.Generic.IList<global::G.TranscriptCustomSpelling>? customSpelling,
            object? autoChapters,
            global::System.Collections.Generic.IList<global::G.Chapter>? chapters,
            object? summaryType,
            object? summaryModel,
            object? summary,
            object? customTopics,
            global::System.Collections.Generic.IList<string>? topics,
            object? sentimentAnalysis,
            global::System.Collections.Generic.IList<global::G.SentimentAnalysisResult>? sentimentAnalysisResults,
            object? entityDetection,
            global::System.Collections.Generic.IList<global::G.Entity>? entities,
            float? speechThreshold,
            object? throttled,
            string? error)
        {
            this.Id = id;
            this.AudioUrl = audioUrl ?? throw new global::System.ArgumentNullException(nameof(audioUrl));
            this.Status = status;
            this.LanguageConfidenceThreshold = languageConfidenceThreshold;
            this.LanguageConfidence = languageConfidence;
            this.SpeechModel = speechModel;
            this.WebhookAuth = webhookAuth;
            this.AutoHighlights = autoHighlights;
            this.RedactPii = redactPii;
            this.Summarization = summarization;
            this.LanguageModel = languageModel ?? throw new global::System.ArgumentNullException(nameof(languageModel));
            this.AcousticModel = acousticModel ?? throw new global::System.ArgumentNullException(nameof(acousticModel));
            this.LanguageCode = languageCode;
            this.LanguageDetection = languageDetection;
            this.Text = text;
            this.Words = words;
            this.Utterances = utterances;
            this.Confidence = confidence;
            this.AudioDuration = audioDuration;
            this.Punctuate = punctuate;
            this.FormatText = formatText;
            this.Disfluencies = disfluencies;
            this.DualChannel = dualChannel;
            this.WebhookUrl = webhookUrl;
            this.WebhookStatusCode = webhookStatusCode;
            this.WebhookAuthHeaderName = webhookAuthHeaderName;
            this.AutoHighlightsResult = autoHighlightsResult;
            this.AudioStartFrom = audioStartFrom;
            this.AudioEndAt = audioEndAt;
            this.WordBoost = wordBoost;
            this.BoostParam = boostParam;
            this.FilterProfanity = filterProfanity;
            this.RedactPiiAudio = redactPiiAudio;
            this.RedactPiiAudioQuality = redactPiiAudioQuality;
            this.RedactPiiPolicies = redactPiiPolicies;
            this.RedactPiiSub = redactPiiSub;
            this.SpeakerLabels = speakerLabels;
            this.SpeakersExpected = speakersExpected;
            this.ContentSafety = contentSafety;
            this.ContentSafetyLabels = contentSafetyLabels;
            this.IabCategories = iabCategories;
            this.IabCategoriesResult = iabCategoriesResult;
            this.CustomSpelling = customSpelling;
            this.AutoChapters = autoChapters;
            this.Chapters = chapters;
            this.SummaryType = summaryType;
            this.SummaryModel = summaryModel;
            this.Summary = summary;
            this.CustomTopics = customTopics;
            this.Topics = topics;
            this.SentimentAnalysis = sentimentAnalysis;
            this.SentimentAnalysisResults = sentimentAnalysisResults;
            this.EntityDetection = entityDetection;
            this.Entities = entities;
            this.SpeechThreshold = speechThreshold;
            this.Throttled = throttled;
            this.Error = error;
        }

        /// <summary>
        /// Initializes a new instance of the <see cref="Transcript" /> class.
        /// </summary>
        public Transcript()
        {
        }
    }
}